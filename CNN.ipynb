{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y6L_q6MSF8lT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "#import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.preprocessing import image\n",
        "import collections\n",
        "import cv2\n",
        "#from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "#import tensorflow as tf\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax , Softmax , functional\n",
        "from torch import flatten\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SdOdb4DeORf"
      },
      "source": [
        "Extracting the train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E-q1OVSeATf",
        "outputId": "09ad44e9-75bb-4816-aa09-28408b580bc5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "TrainFile = \"data.zip\"\n",
        "\n",
        "with ZipFile(TrainFile, 'r') as zip:\n",
        "\tzip.printdir()\n",
        "\tprint('Extracting all the files now...')\n",
        "\tzip.extractall()\n",
        "\tprint('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LAEXUQdeTd7"
      },
      "source": [
        "Haar Cascade function: takes an image finds the faces and returns them cropped \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X5XNsqz2eJca",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def haarCascade(img):\n",
        " face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        " eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        " gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        " faces = face_cascade.detectMultiScale(gray, 1.3, 5,minSize=(30, 30))\n",
        " \n",
        " for (x,y,w,h) in faces:\n",
        "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "    roi_color = img[y:y+h, x:x+w]\n",
        "    return roi_color\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpdqPmqlBNxP",
        "outputId": "3d2a22ae-ccc6-4b0b-8f58-25f1ecad4a3f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "faces = \"faces.zip\"\n",
        "\n",
        "with ZipFile(faces, 'r') as zip:\n",
        "\tzip.printdir()\n",
        "\tprint('Extracting all the files now...')\n",
        "\tzip.extractall()\n",
        "\tprint('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "I2x6aZ9JUqkz",
        "outputId": "fb3621ae-e5d5-41d3-8ee8-36bc3085d784",
        "tags": []
      },
      "outputs": [],
      "source": [
        "path='/content/data/menna/9.jpeg'\n",
        "img =  haarCascade(cv2.imread(path))\n",
        "img = Image.fromarray(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx-DV6uuEbSM"
      },
      "source": [
        "This Loop iterates over the dataset and returns a file called faces that has all the saved images after applying the haar cascade algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ejV_cCaXbaze",
        "tags": []
      },
      "outputs": [],
      "source": [
        "path1 = \"data/*/*\"\n",
        "target_face_size=(388,388)\n",
        "\n",
        "path='faces/'\n",
        "i=0\n",
        "for file in glob.glob(path1):\n",
        "  if('jumana' in file):\n",
        "    img =  haarCascade(cv2.imread(file))\n",
        "    img = Image.fromarray(img)\n",
        "    img = img.resize(target_face_size)\n",
        "    cv2.imwrite(str(path)+'jumana/'+str(i) + '.jpg',np.array(img))\n",
        "    i=i+1\n",
        "  # elif('farida' in file):\n",
        "  #   img =  haarCascade(cv2.imread(file))\n",
        "  #   img = Image.fromarray(img)\n",
        "  #   img = img.resize(target_face_size)\n",
        "  #   cv2.imwrite(str(path)+'farida/'+str(i) + '.jpg',np.array(img))  \n",
        "  #   i=i+1\n",
        "  elif('kroush'in file):\n",
        "    img =  haarCascade(cv2.imread(file))\n",
        "    img = Image.fromarray(img)\n",
        "    img = img.resize(target_face_size)\n",
        "    cv2.imwrite(str(path)+'kroush/'+str(i) + '.jpg',np.array(img))\n",
        "    i=i+1\n",
        "  # elif('menna'in file):\n",
        "  #   img =  haarCascade(cv2.imread(file))\n",
        "  #   img = Image.fromarray(img)\n",
        "  #   img = img.resize(target_face_size)\n",
        "  #   cv2.imwrite(str(path)+'menna/'+str(i) + '.jpg',np.array(img))\n",
        "  #   i=i+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3xYdusLNbx"
      },
      "source": [
        "trans_resize is a way by pytorch to make sure all images are resized. Then we change the dataset to tensors. trainDataLoader takes in the dataset, shuffles it and makes the model take a batch size of one in every time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M2dnDv4bqh2A",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trans_resize=torchvision.transforms.Resize((388,388))\n",
        "trainTransforms = torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), trans_resize ])\n",
        "\n",
        "\n",
        "dataset= torchvision.datasets.ImageFolder('faces',transform=trainTransforms)\n",
        "\n",
        "trainDataLoader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    collate_fn=None,\n",
        "    pin_memory=False,\n",
        " )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXUjlF-tN6hX"
      },
      "source": [
        "**CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzpde34FFpAW"
      },
      "source": [
        "We use GPU to make matrix calculations faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhB5fztK_gk1",
        "outputId": "3347da86-691a-435b-a059-40c45ba9c461",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5NH6Ti8LyzE"
      },
      "source": [
        "This should be the architecture of the Convolutional neural network where we apply a layer of convolution, then we apply relu and then we max pool. after that we add two linear functions then finally we apply the sigmoid function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QKea-fIhlvOj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class FaceNet(Module):\n",
        "  def __init__(self):\n",
        "    # call the parent constructor\n",
        "    super(FaceNet, self).__init__()\n",
        "    # initialize first set of CONV => RELU => POOL layers\n",
        "    self.conv1 = Conv2d(in_channels=3, out_channels=64,\n",
        "      kernel_size=(3,3))\n",
        "    self.relu1 = ReLU()\n",
        "    self.maxpool1 = MaxPool2d(kernel_size=(4, 4), stride=(2, 2))\n",
        "    # initialize second set of CONV => RELU => POOL layers\n",
        "   # self.conv2 = Conv2d(in_channels=32, out_channels=64,\n",
        "     # kernel_size=(3, 3))\n",
        "    #self.relu2 = ReLU()\n",
        "    #self.maxpool2 = MaxPool2d(kernel_size=(5, 5), stride=(2, 2))\n",
        "    \n",
        "    #self.conv3 = Conv2d(in_channels=64, out_channels=128,\n",
        "     # kernel_size=(3,3))\n",
        "    #self.relu3 = ReLU()\n",
        "    #self.maxpool3 = MaxPool2d(kernel_size=(4, 4), stride=(2, 2))\n",
        "    # initialize first (and only) set of FC => RELU layers\n",
        "    self.fc1 = Linear(in_features=2359296, out_features=64)\n",
        "    self.relu3 = ReLU()\n",
        "    \n",
        "    #self.fc2 = Linear(in_features=512, out_features=64)\n",
        "    #self.relu4 = ReLU()\n",
        "    # initialize our softmax classifier\n",
        "    self.fc3 = Linear(in_features=64, out_features=2)\n",
        "    self.logSoftmax = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # pass the input through our first set of CONV => RELU =>\n",
        "    # POOL layers\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    # pass the output from the previous layer through the second\n",
        "    # set of CONV => RELU => POOL layers\n",
        "    #x = self.conv2(x)\n",
        "   # x = self.relu2(x)\n",
        "    #x = self.maxpool2(x)\n",
        "    \n",
        "   # x = self.conv3(x)\n",
        "   # x = self.relu3(x)\n",
        "    #x = self.maxpool3(x)\n",
        "    # flatten the output from the previous layer and pass it\n",
        "    # through our only set of FC => RELU layers\n",
        "    x = flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu3(x)\n",
        "    \n",
        "    #x = self.fc2(x)\n",
        "    #x = self.relu4(x)\n",
        "    \n",
        "    # pass the output to our softmax classifier to get our output\n",
        "    # predictions\n",
        "    x = self.fc3(x)\n",
        "    output = self.logSoftmax(x)\n",
        "    # return the output predictions\n",
        "    return output\n",
        "\n",
        "model = FaceNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6rx46jIM-7L"
      },
      "source": [
        "we used adam func with learning rate -8 so that the model doesnt overfit.\n",
        "And BCE as the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c_MncyXem-eS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "opt = Adam(model.parameters(), lr=1e-8)\n",
        "lossFn = torch.nn.BCEWithLogitsLoss()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhgYysWBNRTb"
      },
      "source": [
        "In this loop, we calculate the total train loss and the total validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmbMM3kAoZ2C",
        "outputId": "6125c4d7-e32a-4a9a-bbf7-678b2cfe7dd9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for e in range(0, 40):\n",
        "\t# set the model in training mode\n",
        "\tmodel.train()\n",
        "\t# initialize the total training and validation loss\n",
        "\ttotalTrainLoss = 0\n",
        "\ttotalValLoss = 0\n",
        "\t# initialize the number of correct predictions in the training\n",
        "\t# and validation step\n",
        "\ttrainCorrect = 0\n",
        "\tvalCorrect = 0\n",
        "\t# loop over the training set\n",
        "\tfor (x, y) in trainDataLoader:\n",
        "\t\t# send the input to the device\n",
        "\t\t(x, y) = (x.to(device), y.to(device))\n",
        "\t\n",
        "\t\ty=functional.one_hot(y,num_classes = 2)\n",
        "\t\tprint('TRUTH',y[0])\n",
        "\n",
        "\t\t# perform a forward pass and calculate the training loss\n",
        "\t\tpred = model(x)\n",
        "\t\tprint('PREDICTION',pred[0])\n",
        "\t\tloss = lossFn(pred.type(torch.FloatTensor), y.type(torch.FloatTensor))\n",
        "\t\t# zero out the gradients, perform the backpropagation step,\n",
        "\t\t# and update the weights\n",
        "\t\topt.zero_grad()\n",
        "\t\tprint(\"LOSS\",loss.item())\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\t\t# add the loss to the total training loss so far and\n",
        "\t\t# calculate the number of correct predictions\n",
        "\t\ttotalTrainLoss += loss\n",
        "\t\ttrainCorrect += (pred.argmax(1) == y.argmax(1) ).type(torch.float).sum().item()\n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6v9XZJJCF96",
        "outputId": "40296da7-ae81-4f3c-9277-36b4eea2d445",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 100.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy\",trainCorrect/17*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1PGMzQPz6qk",
        "outputId": "cd0aa576-4562-4250-abf4-9c65ade53dad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(11.8366, grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "totalTrainLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xmpARmuO7Pkp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSHX_n0J7Pkp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for (x, y) in trainDataLoader:\n",
        "    # send the input to the device\n",
        "    (x, y) = (x.to(device), y.to(device))\n",
        "\n",
        "    \n",
        "\n",
        "    # perform a forward pass and calculate the training loss\n",
        "    pred = model(x)\n",
        "    \n",
        "    img = x[0].to(device,dtype=torch.float).permute(1, 2, 0).detach().cpu().numpy()\n",
        "    \n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    y=functional.one_hot(y,num_classes = 2)\n",
        "    correct = pred.argmax() == y.argmax()\n",
        "    print(correct,pred,y)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
